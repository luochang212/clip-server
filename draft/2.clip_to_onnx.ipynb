{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3cc1e29-bb42-472a-8392-bf325c9057d7",
   "metadata": {},
   "source": [
    "# CLIP 转 ONNX\n",
    "\n",
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d10a677-f29e-4cf1-b661-3c2a236e1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bd44a7-d494-4878-91d2-ca783344d31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:43.870702Z",
     "iopub.status.busy": "2024-11-26T06:35:43.870702Z",
     "iopub.status.idle": "2024-11-26T06:35:43.875301Z",
     "shell.execute_reply": "2024-11-26T06:35:43.875301Z",
     "shell.execute_reply.started": "2024-11-26T06:35:43.870702Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -U onnx onnxruntime onnxruntime-tools onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf28ff4-8df1-4cd2-892b-b24a4691a695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:43.875301Z",
     "iopub.status.busy": "2024-11-26T06:35:43.875301Z",
     "iopub.status.idle": "2024-11-26T06:35:44.546966Z",
     "shell.execute_reply": "2024-11-26T06:35:44.546966Z",
     "shell.execute_reply.started": "2024-11-26T06:35:43.875301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx                      1.17.0\n",
      "onnxruntime               1.20.1\n",
      "onnxruntime-gpu           1.20.1\n",
      "onnxruntime-tools         1.7.0\n",
      "torch                     2.5.1+cu124\n",
      "torchaudio                2.5.1+cu124\n",
      "torchvision               0.20.1+cu124\n"
     ]
    }
   ],
   "source": [
    "# !pip list | grep torch torchvision onnx onnxruntime onnxruntime-tools\n",
    "!pip list | findstr /i \"torch torchvision onnx onnxruntime onnxruntime-tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84d6169-d764-4986-9f2b-4b49518c06b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:44.546966Z",
     "iopub.status.busy": "2024-11-26T06:35:44.546966Z",
     "iopub.status.idle": "2024-11-26T06:35:44.716707Z",
     "shell.execute_reply": "2024-11-26T06:35:44.716707Z",
     "shell.execute_reply.started": "2024-11-26T06:35:44.546966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 28 00:41:28 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P8              4W /  119W |    1199MiB /   8188MiB |     35%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     13800    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     24668      C   C:\\Users\\luoch\\miniconda3\\python.exe        N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1889d60-57b4-45b9-a2a3-8e3120ca3da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:44.717710Z",
     "iopub.status.busy": "2024-11-26T06:35:44.717710Z",
     "iopub.status.idle": "2024-11-26T06:35:44.800155Z",
     "shell.execute_reply": "2024-11-26T06:35:44.800155Z",
     "shell.execute_reply.started": "2024-11-26T06:35:44.717710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Sep_12_02:55:00_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.77\n",
      "Build cuda_12.6.r12.6/compiler.34841621_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2dcabb-b167-4392-89ed-ede8366c6ec3",
   "metadata": {},
   "source": [
    "## 2. 生成图文 Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c836606-eecc-47bf-a13b-2cf41d2607bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:45.937936Z",
     "iopub.status.busy": "2024-11-26T06:35:45.937936Z",
     "iopub.status.idle": "2024-11-26T06:35:47.472097Z",
     "shell.execute_reply": "2024-11-26T06:35:47.472097Z",
     "shell.execute_reply.started": "2024-11-26T06:35:45.937936Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfedfc1-9bcd-46e4-aa05-acd745909624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:35:47.472097Z",
     "iopub.status.busy": "2024-11-26T06:35:47.472097Z",
     "iopub.status.idle": "2024-11-26T06:35:47.477237Z",
     "shell.execute_reply": "2024-11-26T06:35:47.477237Z",
     "shell.execute_reply.started": "2024-11-26T06:35:47.472097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "torch.version.cuda: 12.4\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'workspace'\n",
    "DATA_PATH = 'data'\n",
    "TEXT_ONNX_PATH = 'clip_text.onnx'\n",
    "IMG_ONNX_PATH = 'clip_image.onnx'\n",
    "VIT_ONNX_PATH = 'clip_vit.onnx'\n",
    "\n",
    "img_path = utils.gen_abspath(directory=DATA_PATH, rel_path='cat.JPG')\n",
    "model_path = utils.gen_abspath(directory='./', rel_path=MODEL_PATH)\n",
    "\n",
    "text_onnx_path = utils.gen_abspath(directory=MODEL_PATH, rel_path=TEXT_ONNX_PATH)\n",
    "img_onnx_path = utils.gen_abspath(directory=MODEL_PATH, rel_path=IMG_ONNX_PATH)\n",
    "vit_onnx_path = utils.gen_abspath(directory=MODEL_PATH, rel_path=VIT_ONNX_PATH)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')\n",
    "print(f'torch.version.cuda: {torch.version.cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9131d141-3063-4eda-975d-3f3cd1f48d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T06:46:18.753558Z",
     "iopub.status.busy": "2024-11-26T06:46:18.752952Z",
     "iopub.status.idle": "2024-11-26T06:46:23.741904Z",
     "shell.execute_reply": "2024-11-26T06:46:23.741617Z",
     "shell.execute_reply.started": "2024-11-26T06:46:18.753558Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载模型和处理器\n",
    "model_name = 'openai/clip-vit-base-patch32'\n",
    "model = CLIPModel.from_pretrained(model_name, cache_dir=model_path)\n",
    "processor = CLIPProcessor.from_pretrained(model_name, cache_dir=model_path)\n",
    "\n",
    "model.eval()\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b67b434-c94a-4349-a8e0-65071a7de14f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:35:32.090768Z",
     "iopub.status.idle": "2024-11-26T06:35:32.090768Z",
     "shell.execute_reply": "2024-11-26T06:35:32.090768Z",
     "shell.execute_reply.started": "2024-11-26T06:35:32.090768Z"
    }
   },
   "outputs": [],
   "source": [
    "# 文本 embedding\n",
    "def get_text_embedding(texts, device):\n",
    "    inputs = processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_text_features(**inputs)\n",
    "    text_embeddings = embeddings / embeddings.norm(p=2, dim=-1, keepdim=True)\n",
    "    return text_embeddings\n",
    "\n",
    "# 图片 embedding\n",
    "def get_image_embedding(image_path, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_image_features(**inputs)\n",
    "    image_embeddings = embeddings / embeddings.norm(p=2, dim=-1, keepdim=True)\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a7f825-76d5-4789-8181-367f0d65cd9d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:29:31.324612Z",
     "iopub.status.idle": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply.started": "2024-11-26T06:29:31.324612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"A photo of a cat\", \"A picture of a dog\"]\n",
    "text_embeddings = get_text_embedding(texts, device=device)\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4696b6c5-17ff-463b-b7dc-51109bd38753",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:29:31.324612Z",
     "iopub.status.idle": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply.started": "2024-11-26T06:29:31.324612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embedding = get_image_embedding(img_path, device=device)\n",
    "image_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85834ab-bba7-4209-b76c-eb3240b88128",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:29:31.324612Z",
     "iopub.status.idle": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply": "2024-11-26T06:29:31.324612Z",
     "shell.execute_reply.started": "2024-11-26T06:29:31.324612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2863, 0.2313], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = cosine_similarity(text_embeddings, image_embedding)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14d1b1d1-5154-4d2a-a29a-d8c12db0d0e0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:29:31.327385Z",
     "iopub.status.idle": "2024-11-26T06:29:31.327385Z",
     "shell.execute_reply": "2024-11-26T06:29:31.327385Z",
     "shell.execute_reply.started": "2024-11-26T06:29:31.327385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2863],\n",
       "        [0.2313]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = (text_embeddings @ image_embedding.T)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aed5e4-e705-46cc-b66e-1d9e6ce3ad5a",
   "metadata": {},
   "source": [
    "## 3. 转换为 ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf5afee-46eb-4e4e-ab36-a3082a174742",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.701652Z",
     "iopub.status.idle": "2024-11-26T06:21:32.701652Z",
     "shell.execute_reply": "2024-11-26T06:21:32.701652Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.701652Z"
    }
   },
   "outputs": [],
   "source": [
    "def export_text_model_to_onnx(model, output_path, device):\n",
    "    # 导出文本模型部分\n",
    "    dummy_input = torch.randint(0, 77, (1, 77)).to(device)  # 假设序列长度为 77\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model.text_model,\n",
    "        dummy_input,\n",
    "        output_path,\n",
    "        input_names=[\"input_ids\"],\n",
    "        output_names=[\"text_features\"],\n",
    "        dynamic_axes={\"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"}, \"text_features\": {0: \"batch_size\"}},\n",
    "        opset_version=20\n",
    "    )\n",
    "\n",
    "def export_image_model_to_onnx(model, output_path, device):\n",
    "    # 导出视觉模型部分\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)   # 假设图片大小为 (3, 224, 224)\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model.vision_model,\n",
    "        dummy_input,\n",
    "        output_path,\n",
    "        input_names=[\"pixel_values\"],\n",
    "        output_names=[\"image_features\"],\n",
    "        dynamic_axes={\"pixel_values\": {0: \"batch_size\"}, \"image_features\": {0: \"batch_size\"}},\n",
    "        opset_version=20\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d044d74-495b-4a9b-a10a-9aed849f6274",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.701652Z",
     "iopub.status.idle": "2024-11-26T06:21:32.703677Z",
     "shell.execute_reply": "2024-11-26T06:21:32.701652Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.701652Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导出文本模型\n",
    "export_text_model_to_onnx(model,\n",
    "                          output_path=text_onnx_path,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b701629-45d0-44a1-a155-14b6d9c19b4a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.703677Z",
     "iopub.status.idle": "2024-11-26T06:21:32.703677Z",
     "shell.execute_reply": "2024-11-26T06:21:32.703677Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.703677Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导出图片模型\n",
    "export_image_model_to_onnx(model,\n",
    "                           output_path=img_onnx_path,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e392c8-bb86-4e0e-90e0-d949b45c1d65",
   "metadata": {},
   "source": [
    "## 4. 验证 ONNX 模型\n",
    "\n",
    "### 1）文本模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f765f650-cf7f-4bad-9bb7-5f06537fd249",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.703677Z",
     "iopub.status.idle": "2024-11-26T06:21:32.703677Z",
     "shell.execute_reply": "2024-11-26T06:21:32.703677Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.703677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 77, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 ONNX 模型\n",
    "text_session = ort.InferenceSession(text_onnx_path)\n",
    "\n",
    "# 假设输入文本序列\n",
    "dummy_input = np.random.randint(0, 77, (1, 77)).astype(np.int64)\n",
    "\n",
    "# 推理\n",
    "outputs = text_session.run(None, {\"input_ids\": dummy_input})\n",
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "669c9b5c-461c-49ca-90a8-84de961d5d4c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.705682Z",
     "iopub.status.idle": "2024-11-26T06:21:32.705682Z",
     "shell.execute_reply": "2024-11-26T06:21:32.705682Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.705682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pooling: (1, 512)\n",
      "Last Position: (1, 512)\n"
     ]
    }
   ],
   "source": [
    "output = outputs[0]\n",
    "\n",
    "# 平均池化\n",
    "ap_text_embedding = np.mean(output, axis=1)\n",
    "print(f'Average Pooling: {ap_text_embedding.shape}')\n",
    "\n",
    "# 取最后一个位置的特征向量\n",
    "lp_text_embedding = output[:, 0, :]\n",
    "print(f'Last Position: {lp_text_embedding.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89909a73-aef3-4598-b2fe-2b324ff9eb78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T03:16:25.380926Z",
     "iopub.status.busy": "2024-11-26T03:16:25.378915Z",
     "iopub.status.idle": "2024-11-26T03:16:25.391160Z",
     "shell.execute_reply": "2024-11-26T03:16:25.389342Z",
     "shell.execute_reply.started": "2024-11-26T03:16:25.380926Z"
    }
   },
   "source": [
    "### 2）图片模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b10d07b-e1b6-4c31-8260-2f4c29cbce63",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.705682Z",
     "iopub.status.idle": "2024-11-26T06:21:32.705682Z",
     "shell.execute_reply": "2024-11-26T06:21:32.705682Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.705682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载 ONNX 模型\n",
    "image_session = ort.InferenceSession(img_onnx_path)\n",
    "\n",
    "# 假设输入图片\n",
    "dummy_image = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "\n",
    "# 推理\n",
    "outputs = image_session.run(None, {\"pixel_values\": dummy_image})\n",
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fcfc42-6e09-4ccf-bd05-34d3d262bbbb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.707687Z",
     "iopub.status.idle": "2024-11-26T06:21:32.707687Z",
     "shell.execute_reply": "2024-11-26T06:21:32.707687Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.707687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output name: image_features, Shape: dim {\n",
      "  dim_param: \"batch_size\"\n",
      "}\n",
      "dim {\n",
      "  dim_param: \"Addimage_features_dim_1\"\n",
      "}\n",
      "dim {\n",
      "  dim_param: \"Addimage_features_dim_2\"\n",
      "}\n",
      "\n",
      "Output name: 1274, Shape: dim {\n",
      "  dim_param: \"batch_size\"\n",
      "}\n",
      "dim {\n",
      "  dim_param: \"Addimage_features_dim_2\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载 ONNX 模型\n",
    "img_onnx_model = onnx.load(img_onnx_path)\n",
    "\n",
    "# 检查输出节点\n",
    "for output in img_onnx_model.graph.output:\n",
    "    print(f\"Output name: {output.name}, Shape: {output.type.tensor_type.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c514ce79-f74d-4415-9ca7-2628a89f028c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.707687Z",
     "iopub.status.idle": "2024-11-26T06:21:32.707687Z",
     "shell.execute_reply": "2024-11-26T06:21:32.707687Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.707687Z"
    }
   },
   "outputs": [],
   "source": [
    "# 检查模型的有效性\n",
    "onnx.checker.check_model(img_onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a08c13-cad3-489e-a317-dc009c7fb444",
   "metadata": {},
   "source": [
    "## 5. 直接计算图文相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee8ce4ba-3373-4d14-9936-a465567e47c7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.709692Z",
     "iopub.status.idle": "2024-11-26T06:21:32.709692Z",
     "shell.execute_reply": "2024-11-26T06:21:32.709692Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.709692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19.7188, 24.3281],\n",
       "         [19.9688, 24.9375],\n",
       "         [19.6406, 24.6875],\n",
       "         [19.8438, 24.7344],\n",
       "         [19.9688, 24.7031],\n",
       "         [19.7812, 24.9062],\n",
       "         [20.1719, 24.6719],\n",
       "         [19.4375, 24.7500],\n",
       "         [19.8125, 24.5000],\n",
       "         [19.5781, 24.8906]], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<MmBackward0>),\n",
       " tensor([[19.7188, 19.9688, 19.6406, 19.8438, 19.9688, 19.7812, 20.1719, 19.4375,\n",
       "          19.8125, 19.5781],\n",
       "         [24.3281, 24.9375, 24.6875, 24.7344, 24.7031, 24.9062, 24.6719, 24.7500,\n",
       "          24.5000, 24.8906]], device='cuda:0', dtype=torch.float16,\n",
       "        grad_fn=<TBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, pre = clip.load(\"ViT-B/32\", device=device, download_root=model_path)\n",
    "npx = m.visual.input_resolution\n",
    "dummy_image = torch.randn(10, 3, npx, npx).to(device)\n",
    "dummy_texts = clip.tokenize([\"quick brown fox\", \"lorem ipsum\"]).to(device)\n",
    "m.forward(dummy_image, dummy_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a85e6320-4243-4942-8353-fd5074a07443",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-26T06:21:32.709692Z",
     "iopub.status.idle": "2024-11-26T06:21:32.709692Z",
     "shell.execute_reply": "2024-11-26T06:21:32.709692Z",
     "shell.execute_reply.started": "2024-11-26T06:21:32.709692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[19.72, 24.33],\n",
       "        [19.95, 24.94],\n",
       "        [19.66, 24.7 ],\n",
       "        [19.86, 24.77],\n",
       "        [19.97, 24.72],\n",
       "        [19.78, 24.92],\n",
       "        [20.16, 24.67],\n",
       "        [19.44, 24.75],\n",
       "        [19.81, 24.52],\n",
       "        [19.6 , 24.9 ]], dtype=float16),\n",
       " array([[19.72, 19.95, 19.66, 19.86, 19.97, 19.78, 20.16, 19.44, 19.81,\n",
       "         19.6 ],\n",
       "        [24.33, 24.94, 24.7 , 24.77, 24.72, 24.92, 24.67, 24.75, 24.52,\n",
       "         24.9 ]], dtype=float16)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    m,\n",
    "    (dummy_image, dummy_texts),\n",
    "    vit_onnx_path,\n",
    "    export_params=True,\n",
    "    input_names=[\"IMAGE\", \"TEXT\"],\n",
    "    output_names=[\"LOGITS_PER_IMAGE\", \"LOGITS_PER_TEXT\"],\n",
    "    opset_version=20,\n",
    "    dynamic_axes={\n",
    "        \"IMAGE\": {\n",
    "            0: \"image_batch_size\",\n",
    "        },\n",
    "        \"TEXT\": {\n",
    "            0: \"text_batch_size\",\n",
    "        },\n",
    "        \"LOGITS_PER_IMAGE\": {\n",
    "            0: \"image_batch_size\",\n",
    "            1: \"text_batch_size\",\n",
    "        },\n",
    "        \"LOGITS_PER_TEXT\": {\n",
    "            0: \"text_batch_size\",\n",
    "            1: \"image_batch_size\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "ort_sess = ort.InferenceSession(vit_onnx_path)\n",
    "result = ort_sess.run(\n",
    "    [\"LOGITS_PER_IMAGE\", \"LOGITS_PER_TEXT\"],\n",
    "    {\"IMAGE\": dummy_image.cpu().numpy(), \"TEXT\": dummy_texts.cpu().numpy()})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a666c2-d814-473e-8b86-ea42e1477729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T08:49:50.949293Z",
     "iopub.status.busy": "2024-11-26T08:49:50.948771Z",
     "iopub.status.idle": "2024-11-26T08:49:50.957433Z",
     "shell.execute_reply": "2024-11-26T08:49:50.956115Z",
     "shell.execute_reply.started": "2024-11-26T08:49:50.949293Z"
    }
   },
   "source": [
    "参考：\n",
    "\n",
    "- [triton-inference-server/tutorials](https://github.com/triton-inference-server/tutorials)\n",
    "- [preprocessing](https://github.com/triton-inference-server/python_backend/blob/main/examples/preprocessing/README.md)\n",
    "- [Model_Ensembles](https://github.com/triton-inference-server/tutorials/blob/main/Conceptual_Guide/Part_5-Model_Ensembles/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e9e35-6e9b-4d7a-a4e7-652447573e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
